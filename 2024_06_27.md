머신러닝 분류 방식

1.로지스틱 회귀
   
     이진분류에 용이(0 or 1)
   
     시그모이드 함수 사용
   
     확률과 관련되어 있음

2.서포트 벡터머신

     선으로 데이터를 분류
     
     선= 결정경계
        
     결정경계 근처에 있는 이상치 처리방식(하드 마진, 소프트 마진)
        
     커널을 사용하면 비선형으로 묶을 수 있음
        
3.결정트리

     이상치가 많이 존재하는 경우 사용하면 좋음
        
     순도와 불확싱성을 조절해서 분류
        
     순도와 불확싱성은 엔트로피와 지니계수에 의해 구함

앙상블 학습

     학습기을 여러번 반복해서 그 결과를 종합해 학습기을 강화하는 학습 (weak learner -> strong learner)
        
     앙상블 학습에는 2가지 방식이 존재
        
     1) 배깅: 같은 학습기을 다른 데이터셋으로 여러번 반복해 그 결과를 종합하는 방식 (병렬 방식)
        
             예) 랜덤 포레스트
                
     2) 부스팅: 하나의 학습기를 학습한 후 보완해서 다시 학습하고 보완, 이 과정을 반복하는 방식 (순차 방식)
        
              예) 에이다 부스트, 그래디언트 부스팅
                 
     초반에는 배깅이 많이 사용, 부스팅이 나온 후 부스팅 많이 사용( 오류를 수정하면서 발전하는 부스팅이 더 좋음)

에이다 부스트

     부스팅 방식과 동일하지만 학습했을 때 틀렸는 부분에 더 높은 가중치를 부과하는 방식

     자세한 내용은 AdaBoost.ipynb를 참조
        
![Untitled](https://github.com/Copy-Fox/Study/assets/154932134/5dafb3a1-bb8d-4898-afb0-14d2f150b349)

결정트리 구조로 에이다 부스트 한 결과

![bfdb4074-4f7e-4345-9e26-8678134f4b82](https://github.com/Copy-Fox/Study/assets/154932134/6068557f-1185-4355-9a05-4f151a719985)

로지스틱 회귀로 에이다 부스트 한 결과

![eea3e9e4-5fb4-4842-9c36-0dee3f3f2e54](https://github.com/Copy-Fox/Study/assets/154932134/b3e7219c-24ee-48a1-a299-0c9c6501c999)

      적절한 구조가 나오지 않아서 로지스틱 회귀는 에이다 부스트에 적합하지 않음

서포트 벡터 머신으로 에이다 부스트 한 결과
         
      빠른 시간안에 결과가 나오지 않음
         
      에이다 부스트는 약하지만 빠른 학습기를 사용하는 것이 효율이 좋기 때문에 연산이 많이 필요한 서포트 벡터 머신은 에이다 부스트에 적합하지 않음

=> 에이다 부스트를 사용할려면 결정트리 구조를 사용하는 것이 좋다.

Cascade에이다 부스트

      여러개의 에이다 부스트를 사용하는 부스팅 방식

      에이다 부스트를 사용해서 적절하지 못한 부분을 쳐내고 다시 에이다 부스트를 써서 적절하지 못한 부분을 쳐내는 것을 반복해서 필요한 부분만 추려내는 원리

      에이다 부스트와의 차이점: 에이다 부스트는 틀린 부분에 가중치를 주지만, cascade는 틀린부분은 버리고 맞는 부분만 가져감
